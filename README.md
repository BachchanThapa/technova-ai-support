# technova-ai-support
# TechNova Chat ğŸ—¨ï¸

Tools I used in this small full-stack project to build a **document-grounded chatbot** for TechNova AB.

- **Frontend:** Vite + React
- **Backend:** Express (in `packages/core/api`)
- **RAG / Search:** Supabase (`documents` table + `match_documents` RPC)
- **LLM:** Local Ollama (`llama3.1:8b`)
- **UI Components:** Local packages in `packages/base/*` (School-- basic style)

This explains **how the request travels** through the app and **where the files live** making it easier to follow the code.

---

## ğŸ” How the chat works

1. User types a question in the **React chat UI**.
2. Frontend sends `POST /rag/chat` to the **Express API**.
3. API runs a **RAG pipeline**:
   - search TechNova FAQ in Supabase
   - check if the match is relevant
   - if yes â†’ build prompt and ask Ollama
   - if no â†’ send a polite fallback
4. API returns JSON: `{ answer, sources[] }`
5. React shows:
   - the assistant bubble
   - **`Source: TechNova FAQ`** (so we can prove it came from our document)

---
## ğŸ“¸ Supabase table

Screenshot of the Supabase table where the TechNova FAQ/policy text is stored:

![Supabase table](docs-supabase-table.png)

---

## ğŸ§­ Request flow (RAG pipeline)

```text
React UI (chat)
   â”‚
   â””â”€â”€ POST /rag/chat  (through Vite proxy â†’ http://localhost:8787)
         â”‚
         â””â”€â”€ Express route (packages/core/api/routes/chat.js)
               â”‚
               â””â”€â”€ Chat controller (packages/core/api/controller/chatController.js)
                     â”‚
                     â””â”€â”€ RAG chain (packages/core/api/lib/*)
                           â”‚
                           â”œâ”€â”€ calls Supabase RPC "match_documents"
                           â”‚       to search TechNova FAQ chunks
                           â”‚
                           â”œâ”€â”€ evaluates relevance  (guardrail)
                           â”‚
                           â”œâ”€â”€ if NO â†’ build polite refusal
                           â”‚   e.g. "Informationen saknas i dokumenten."
                           â”‚
                           â””â”€â”€ if YES â†’
                                   â€¢ build prompt = system + history + FAQ chunks
                                   â€¢ send to Ollama (llama3.1:8b)
                                   â€¢ get draft answer
                                   â€¢ attach sources (FAQ snippets)
                                         â†“
                              JSON back to React
